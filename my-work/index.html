<!doctype html>
<html>
  <head>

    

    <meta name="description" content=" - Jack Brookes">

    <link rel="shortcut icon" type="image/png" href="/static/me_circ.png">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Roboto:400,400i,700,700i|Roboto+Mono:400,400i,700" rel="stylesheet">
    <link rel="stylesheet" href="/static/style.css">

    <meta name="twitter:card" content="summary" />           
    <meta name="twitter:site" content="@jackbrookes" />
    <meta name="twitter:title" content="
  My work
" />
    <meta name="twitter:description" content=" - Jack Brookes" />



    <title>
  My work
 - Jack Brookes</title>

    
  </head>
  <body>
    <div id="navbar-container" class="mobile-padded">
      <ul id="navbar">
        <li class="navbutton">
          <a href="/"  class="sweep">Home</a>
        </li>
        <li class="navbutton">
          <a href="/my-work/" class="sweep current"  class="sweep">My work</a>
        </li>
        <li class="navbutton">
          <a href="/about/"  class="sweep">About</a>
        </li>
        <li class="navbutton">
          <a href="/contact/"  class="sweep">Contact</a>
        </li>
      
      </ul>
    </div>
    <div id="centred-container">
      <div id="main">
        <div id="content">
          
   <div class="card cf">
    
    <h1 class="title">My work
    </h1>
    
    
    <div class="inner-card">
    <h2>Software portfolio</h2>

<p>My open sourced work can be found at my <a href="http://github.com/jackbrookes">GitHub</a>.</p>

<p>Highlights:</p>

<ul>
<li><a href="http://immersivecognition.github.io/unity-experiment-framework">Unity Experiment Framework (UXF)</a> - Framework for human behaviour experiments in Unity
<ul>
<li><a href="https://github.com/jackbrookes/uxf-web-settings">UXF Web Settings</a> - Unity package that allows experiments built in UXF to read their settings from the web rather than locally.</li>
<li><a href="https://github.com/jackbrookes/uxf-s3-uploader">UXF S3 Uploader</a> - Unity package that allows experiments built in UXF to upload their files to an Amazon Web Services S3 bucket.</li>
</ul></li>
<li><a href="https://github.com/immersivecognition/vr-demo-pack">VR Demo Pack</a> - Unity package that allows developers to add an avatar, viewable in 3rd person, to their task for presentation and video purposes.</li>
<li><a href="https://github.com/jackbrookes/bouncebeat">BounceBeat</a> - VR musical physics sandbox game made in Unity.</li>
<li><a href="https://github.com/jackbrookes/vr-graph-intersection">Unnamed, unfinished game</a> - VR puzzle game where the goal is to create faces from nodes that do not create intersections in a 3D graph.</li>
<li><a href="https://github.com/jackbrookes/eyeballs-vr-demo">Eyeballs VR Demo</a> - VR demo made in Unity that allows you to detach your eyes from your head.</li>
<li><a href="https://stackoverflow.com/users/5025009/jack-brookes">Active StackOverflow user</a></li>
</ul>

<h2>Unity experiments</h2>

<p>During my PhD I have developed several virtual reality experiments to examine human behaviour, mostly in the area of human sensorimotor decision making. All were developed in Unity and most take advantage of my Unity Experiment Framework.</p>

<h3>Interceptive timing</h3>

<p>This task examines the interceptive timing ability of children and adults. Crucially, VR allows the task to be made 3D - which means we can more reliably discern spatial and temporal errors separately. The gamification of the interceptive timing task means children enjoy taking part in the studies.</p>

<p><video controls width="500" muted>
  <source src="/static/image/interceptive-timing-vr.mp4" type="video/mp4">
  Your browser does not support HTML5 video.
</video></p>

<h3>Intrinsic vs extrinsic costs in sensorimotor decision making</h3>

<p>Here we present participants with a series of choices between two objects. These objects differ in their <em>extrinsic</em> costs in terms of number of stars (i.e. points), and also their <em>intrinsic</em> costs because they have certain distance and timing constraints.</p>

<p><img src="/static/image/bubbles.jpg" width="500"/></p>

<h3>Postural sway assessment tool</h3>

<p>This task measures the participant's head position across three conditions: vision, no vision, and the oscillating room intervention. VR here these manipulations easy, and allows researchers to examine the participants ability to use vision to adjust balance. This project is available free &amp; <a href="https://github.com/immersivecognition/posture-assessment-vr">open source</a>. </p>

<p><video controls width="500" muted>
  <source src="/static/image/sway.mp4" type="video/mp4">
  Your browser does not support HTML5 video.
</video></p>

<h3>Action-bandits</h3>

<p>In my PhD I study how different types of errors (selection error, movement error) change the way we learn about our world. In this experiment, participants must physically swipe through one of two targets. Virtual Reality allows me to easily manipulate the rate of movement errors the participant believes they are making, by hiding the position of the hand when needed.  </p>

<p><video controls width="500" muted>
  <source src="/static/image/action-bandits.mp4" type="video/mp4">
  Your browser does not support HTML5 video.
</video></p>

<h3>Prehension</h3>

<p>Reach-to-grasp behaviours have been studied for decades, but only recently VR has allowed new experiments to be created. Here, we examine the effects of removing haptics or vision of the hand when reaching for an object using the VR experiment I developed.</p>

<p class="noimage">No image :(</p>

<h3>Haptic Handwriting</h3>

<p>Handwriting is an important life skill, but many children underperform. Here I developed a simple handwriting task that allows children to virtually practice handwriting with haptic interventions that potentially improve learning rate. The Unity application communicates to a Phantom Omni haptic pen system. We tested this in a primary school, which was then features on the BBC Inside Out program.</p>

<p><img src="/static/image/handwriting.png" width="500"/></p>

<h3>Golf</h3>

<p>A great challenge in learning is understanding generalisation. Humans and other animals manage to quickly generalise abilities learned in one domain to another one. Virtual Reality poses a massive opportunity for training of skills ranging from surgery to customer service. For this to be useful, the skills learned in VR need to transfer to the real world. We are using this virtual reality golf task I developed to examine how we generalise skills learned in one medium to another.</p>

<p><img src="/static/image/golf.png" width="500"/></p>

<h3>Treasure chest bandits</h3>

<p>Continuing the work done in my PhD on learning in the context of movement errors, I developed a similar task that removed the motor aspect of the task, and transformed it into a 2-stage decision making task. This is done on a computer monitor rather than in VR.</p>

<p><video controls width="500" muted>
  <source src="/static/image/treasure.mp4" type="video/mp4">
  Your browser does not support HTML5 video.
</video></p>

<h3>Visuomotor adaptation</h3>

<p>A common motor learning experiment paradigm involves applying a transformation to the environment, such that movements are mapped to a cursor position in a novel way. Here I developed a VR version of this task, which opens up the possibility of developing interesting new interventions, and running these types of experiments on a larger scale.</p>

<p><video controls width="500" muted>
  <source src="/static/image/vmr.mp4" type="video/mp4">
  Your browser does not support HTML5 video.
</video></p>

<h3>Paired associates memorisation</h3>

<p>Memorising a pair of objects, and then recalling the second object after being prompted with the first, is a common way of measuring memory. I developed a VR version of this task, which uses realistic 3D objects rather than the classic image or word based tests in an attempt to be more ecologically valid. We use this task to examine the effects of sleep interventions on memory performance.</p>

<p class="noimage">No image :(</p>

    </div>
</div>
   <div class="card">
    <p style="text-align: center; padding-top:1em;">
      <a href="/static/jack-brookes-cv.pdf" class="download sweep" target="_blank">
        <i class="fa fa-file-text fa-fw" aria-hidden="true"></i>View CV (.pdf)
      </a>
    </p>
  </div>
</div>

        </div>
      </div>
    </div>

    </div>
    <div id="footer-container">
      <div id="footer">
        
        <ul class="footer-ul">
          <li> <i class="fa fa-copyright" aria-hidden="true"></i> Jack Brookes 2019</li>
          <li><a onclick="topFunction()" style="cursor:pointer">Back to top <i class="fa fa-fw fa-long-arrow-up" aria-hidden="true"></i></a></li>
        </ul>
        
      </div>
    </div>

    <script>
    // When the user clicks on the button, scroll to the top of the document
    function topFunction() {
        document.body.scrollTop = 0;
        document.documentElement.scrollTop = 0;
    }
    </script>


  </body>
</html>